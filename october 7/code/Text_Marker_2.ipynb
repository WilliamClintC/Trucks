{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process**\n",
    "\n",
    "1. open text file\n",
    "\n",
    "2. record the section header pattern number.number.number\n",
    "\n",
    "3. if a section (A) is found within another section (B). A will be copied into B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "def text_collect(filename):\n",
    "    pattern = re.compile(r\"^\\d+\\.\\d+\\.\\d+\")\n",
    "    sections = []\n",
    "    current_section = None\n",
    "    collected_text = []\n",
    "\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            match = pattern.match(line)\n",
    "            if match:\n",
    "                if current_section:\n",
    "                    sections.append({\n",
    "                        \"Section\": current_section,\n",
    "                        \"Text\": ' '.join(collected_text),\n",
    "                        \"Zoning Location\": filename\n",
    "                    })\n",
    "                current_section = match.group()\n",
    "                collected_text = [line[len(current_section):].strip()]\n",
    "            elif current_section:\n",
    "                collected_text.append(line.strip())\n",
    "\n",
    "        if current_section:\n",
    "            sections.append({\n",
    "                \"Section\": current_section,\n",
    "                \"Text\": ' '.join(collected_text),\n",
    "                \"Zoning Location\": filename\n",
    "            })\n",
    "\n",
    "    with open(f\"grouped_text.pkl\", 'ab') as pkl_file:\n",
    "        pickle.dump(sections, pkl_file)\n",
    "\n",
    "#clear the file\n",
    "with open(\"grouped_text.pkl\", 'wb') as pkl_file:\n",
    "    pass  # This will clear the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x96 in position 165: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m                 file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirpath, filename)\n\u001b[1;32m      8\u001b[0m                 text_collect(file_path)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mrun_text_collect_on_all_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/will/Desktop/Trucks/october 7/code/folder/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mrun_text_collect_on_all_files\u001b[0;34m(root_directory)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      7\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirpath, filename)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mtext_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mtext_collect\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m collected_text \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x96 in position 165: invalid start byte"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def run_text_collect_on_all_files(root_directory):\n",
    "    for dirpath, _, filenames in os.walk(root_directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                text_collect(file_path)\n",
    "\n",
    "import os\n",
    "\n",
    "def run_text_collect_on_all_files(root_directory):\n",
    "    for dirpath, _, filenames in os.walk(root_directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                text_collect(content)\n",
    "\n",
    "                \n",
    "\n",
    "run_text_collect_on_all_files('/Users/will/Desktop/Trucks/october 7/code/folder/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory: /Users/will/Desktop/Trucks/october 7/code/folder/\n",
      "\t.DS_Store\n",
      "Found directory: /Users/will/Desktop/Trucks/october 7/code/folder/set1\n",
      "\t.DS_Store\n",
      "\tCA_SanLuisObispo.txt\n",
      "\tAK_Homer.txt\n",
      "Found directory: /Users/will/Desktop/Trucks/october 7/code/folder/set0\n",
      "\t.DS_Store\n",
      "\tWA_Redmond.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_directory = '/Users/will/Desktop/Trucks/october 7/code/folder/'\n",
    "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "    print(f'Found directory: {dirpath}')\n",
    "    for file_name in filenames:\n",
    "        print(f'\\t{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_collect('AK_Homer.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "# Load the pickle file\n",
    "with open('grouped_text.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Function to find and replace patterns\n",
    "def replace_patterns(data):\n",
    "    pattern = re.compile(r'\\d+\\.\\d+\\.\\d+')\n",
    "    \n",
    "    for entry in data:\n",
    "        text = entry.get('Text')\n",
    "        matches = pattern.findall(text)\n",
    "        \n",
    "        for match in matches:\n",
    "            collected_texts = []\n",
    "            for section_entry in data:\n",
    "                section = section_entry.get('Section')\n",
    "                if match in section:\n",
    "                    collected_texts.append(section_entry.get('Text'))\n",
    "            replacement_text = ' '.join(collected_texts)\n",
    "            text = text.replace(match, replacement_text)\n",
    "        entry['Text'] = text\n",
    "\n",
    "    with open('modified_grouped_text.pkl', 'ab') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "#clear the file\n",
    "with open(\"modified_grouped_text.pkl\", 'wb') as pkl_file:\n",
    "    pass  # This will clear the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace patterns in the data\n",
    "replace_patterns(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
