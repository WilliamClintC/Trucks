{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import regex as re\n",
    "import xlwt\n",
    "import glob\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from statistics import mode\n",
    "import collections\n",
    "import itertools\n",
    "from iteration_utilities import deepflatten\n",
    "import csv\n",
    "from collections import Counter \n",
    "import timeit\n",
    "\n",
    "\n",
    "numbers = r\"\"\"(?x)          # Turn on free spacing mode\n",
    "            (\n",
    "              #^a(?=\\s)|     # Here we match a at the start of string before  whitespace\n",
    "              #[-]?[0-9]+[,.]?[0-9]*[\\/][0-9]+[,.]?[0-9]*|  # new numbers\n",
    "              (?<!-\\d*\\.*|\\.|table\\s\\d*\\.*\\d*\\.*\\d*\\.*)\\b[0-9]+[,.]?[0-9]*|  # new numbers\n",
    "              (?<!-\\d*\\.*|\\.|table\\s\\d*\\.*\\d*\\.*\\d*\\.*)\\b\\d*\\.?\\,?\\\\?\\d+ # HERE we match one or more digits\n",
    "              #\\b            # Initial word boundary \n",
    "              #(?:\n",
    "              #    one|two|three|four|five|six|seven|eight|nine|ten| \n",
    "              #    eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen| \n",
    "              #    eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty| \n",
    "              #    ninety|hundred|thousand|half\n",
    "              #)             # A list of alternatives\n",
    "              #\\b            # Trailing word boundary\n",
    "              )\"\"\"   \n",
    "\n",
    "def fnote_fix(string):\n",
    "    nums = re.findall(numbers, string, flags=re.IGNORECASE)\n",
    "\n",
    "    nums_pr = [n for n in nums if \",\" in n]\n",
    "\n",
    "    for n, num in enumerate(nums_pr):\n",
    "        newnum = num.split(\",\")\n",
    "        for i, j in enumerate(newnum):\n",
    "            if len(j) > 3:\n",
    "                newnum[i] = j[:3]\n",
    "                finnum = \"\".join(newnum)\n",
    "                string = re.sub(str(num), str(finnum), string)\n",
    "\n",
    "    return string\n",
    "\n",
    "def pre_processing(lines):\n",
    "    lines1 = re.sub(r'\"\\d+', '', lines)\n",
    "    lines2 = re.sub(r'[^\\x00-\\x7f]', r'-', lines1)\n",
    "    lines3 = ' '.join(lines2.split())\n",
    "    lines4 = re.sub(r'\\n', ' ', lines3)  # takes away all new line indicators and replaces with a space, fixed a problem where regex wasn't catching some words when ran in the loop\n",
    "    lines5 = re.sub(r'\\t', ' ', lines4)  # removes \\t characters\n",
    "    lines6 = re.sub(r'\\\\', '', lines5)\n",
    "    lines7 = re.sub(r'http\\S+', '', lines6)\n",
    "    lines8 = re.sub(r'\\d+\\.\\d{3,}\\.*\\d*\\.*\\d*|\\d+\\.\\d+\\.\\d+|\\+\\-+|\\-{3,}', '', lines7)\n",
    "    lines9 = re.sub(r'\\[\\d+\\]', '', lines8)\n",
    "    lines10 = re.sub(r'=', ' ', lines9)\n",
    "    lines11 = re.sub(r'\\bsf\\b', \"square feet\", lines10)\n",
    "    lines12 = re.sub(\n",
    "        r'\\b(Sterling\\sCodifiers\\,\\sInc\\.|Article|Chapter|Section|SECTION|Sections|Subsection|Sec|Prior\\scode|Code|Ordinance|Ord|Lots|through|pg|pgs|Part)\\b\\.*\\s*(No\\.)*\\s*\\d*\\w*\\:*\\.*\\-*\\d*\\-*\\d*\\,*\\.*\\s*(and)*\\s*\\d*\\-*\\d*\\-*\\d*\\,*\\s*(and)*\\s*\\d*\\-*\\d*\\-*\\d*',\n",
    "        '', lines11)\n",
    "    lines13 = re.sub(r'\\bAmended\\sby\\sOrd\\.\\sNo\\.\\s\\d+\\,\\s\\d+\\/d+\\/\\d+|Amended\\s\\d{4}\\b|amended\\s\\d{1,2}\\/\\d{1,2}\\/\\d{1,4}|\\d+\\/\\d+\\/\\d+', '', lines12)\n",
    "    lines14 = re.sub(r'\\d+\\:\\d+', '', lines13)\n",
    "    lines15 = lines14.lower()\n",
    "    lines16 = re.sub(r'\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\b\\s\\d+\\,*\\s\\d{4}', '', lines15)\n",
    "    lines17 = re.sub(r'pg\\.|pgs\\.\\s\\d+\\-\\d+|page\\s\\d+', '', lines16)\n",
    "    lines18 = re.sub(r'\\bft\\.|\\bft\\b', \"feet \", lines17)\n",
    "    lines20 = fnote_fix(str(lines18))\n",
    "    lines21 = re.sub(r'[\",!?*\\[\\]]', '', lines20)\n",
    "    lines22 = re.sub(r';', ' ', lines21)\n",
    "    lines23 = re.sub(r'\\/acre|unit\\/acre|unit\\/net\\sacre|unit\\/gross\\sacre|du\\/ac\\b', \"unit per acre\", lines22)\n",
    "    lines24 = re.sub(r'\\d+\\/\\d+\\/\\d+\\ssterling\\scodifiers\\sinc\\.', '', lines23)\n",
    "    text = lines24.replace(\"(\", \"\").replace(\")\", \"\").replace(\".\", \"\").replace(\":\", \"\").replace(\"/\", \"\")\n",
    "    text = text.replace(\"-\", \"\").replace(\"'\", \"\").replace(\",\", \"\").replace('``', '').replace(\"''\", \"\")\n",
    "    text = text.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def write_to_csv(outputfilename, header, data):\n",
    "    # Create and write to the CSV file\n",
    "    with open(outputfilename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)  # Write the header\n",
    "        for entry in data:\n",
    "            writer.writerow([entry])\n",
    "    print(f\"CSV file created at: {outputfilename}\")\n",
    "\n",
    "def extract_filename(path):\n",
    "    import os\n",
    "    base_name = os.path.basename(path)\n",
    "    return os.path.splitext(base_name)[0]\n",
    "def create_file(filedirect,outputfilename):\n",
    "    filenames = sorted(glob.glob(filedirect + \"*.txt\")) # finds all .txt files in the folder your code is saved in\n",
    "    row_filenames = [extract_filename(path) for path in filenames]\n",
    "    header = [\"Location\", \"Total_word_count\"]\n",
    "    extracted_filenames = [extract_filename(path) for path in filenames]\n",
    "    write_to_csv(outputfilename, header, extracted_filenames)\n",
    "\n",
    "\n",
    "def add_to_csv(outputfilename, counter, entry):\n",
    "    # Read the existing CSV file into a DataFrame\n",
    "    df = pd.read_csv(outputfilename, encoding='ISO-8859-1')\n",
    "    \n",
    "    # Modify the specific cell (counter row, second column)\n",
    "    df.iloc[counter, 1] = entry\n",
    "    \n",
    "    # Save the DataFrame back to the CSV file\n",
    "    df.to_csv(outputfilename, index=False, encoding='ISO-8859-1')\n",
    "\n",
    "\n",
    "def main(filenames, outputfilename,filedirect):\n",
    "    create_file(filedirect,outputfilename)\n",
    "    for counter, loc in enumerate(filenames):\n",
    "        with open(loc, 'r', errors='replace') as file:\n",
    "            lines = file.read()\n",
    "            text = pre_processing(lines)\n",
    "            pre_processing_time = timeit.timeit(lambda: pre_processing(text), number=10)\n",
    "            print(f\"Execution time for pre_processing (1000 iterations): {pre_processing_time} seconds\")\n",
    "\n",
    "            total_word_count= len(text.split())\n",
    "            split_time = timeit.timeit(lambda: len(text.split()), number=10)\n",
    "            print(f\"Execution time for len(text.split()) (1000 iterations): {split_time} seconds\")\n",
    "\n",
    "            add_to_csv(outputfilename, counter, entry=total_word_count)\n",
    "            add_to_csv_time = timeit.timeit(lambda: add_to_csv(outputfilename, counter, entry=0), number=10)\n",
    "            print(f\"Execution time for add_to_csv (1000 iterations): {add_to_csv_time} seconds\")\n",
    "\n",
    "\n",
    "#id=0\n",
    "id = int(os.getenv(\"SGE_TASK_ID\", 1))\n",
    "outputfilename = f\"Total_word_count_{id}.csv\"\n",
    "filedirect = f\"/restricted/projectnb/trucks/William/Mleczko_and_Desmond/nzlud/municipal_codes_all/{id}/\"\n",
    "#f\"C:/Users/clint/Desktop/nzlud/municipal_codes_all/set{id}/\"\n",
    "filenames = sorted(glob.glob(filedirect + \"*.txt\"))\n",
    "#number_of_folders=1\n",
    "main(filenames, outputfilename,filedirect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at: Total_word_count_0.csv\n",
      "Execution time for pre_processing (1000 iterations): 27.96431389998179 seconds\n",
      "Execution time for len(text.split()) (1000 iterations): 0.27912299998570234 seconds\n",
      "Execution time for add_to_csv (1000 iterations): 0.029060399974696338 seconds\n",
      "Execution time for pre_processing (1000 iterations): 38.52287950000027 seconds\n",
      "Execution time for len(text.split()) (1000 iterations): 0.3788734000409022 seconds\n",
      "Execution time for add_to_csv (1000 iterations): 0.025686100008897483 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for id in range(0, number_of_folders):\n",
    "#     outputfilename = f\"Total_word_count_{id}.csv\"\n",
    "#     filedirect = f\"C:/Users/clint/Desktop/nzlud/municipal_codes_all/set{id}/\"\n",
    "#     filenames = sorted(glob.glob(filedirect + \"*.txt\"))\n",
    "#     main(filenames, outputfilename,filedirect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
